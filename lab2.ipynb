{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Oeurnpo6joI"
   },
   "source": [
    "\n",
    "### load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0vvkVUeK6TD0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0                                 Aditya Ingole Deaf          2\n",
      "1  I love the app.! There is no issue but if u co...          1\n",
      "2  So hard to use. The web app failed, and the mo...          0\n",
      "3  I hate that the app makes a sound every time s...          1\n",
      "4  Useless at BSE star MF meet.voice too mych slo...          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the CSV file into a DataFrame\n",
    "df = pd.read_csv('all_data.csv')\n",
    "\n",
    "# display the first 5 rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fawzia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fawzia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OojRlpxt6p1_"
   },
   "source": [
    "### apply text preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1HJDGA5O6_JT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review  sentiment\n",
      "0                                     aditya ingole deaf          2\n",
      "1      i love the app there is no issue but if u coul...          1\n",
      "2      so hard to use the web app failed and the mobi...          0\n",
      "3      i hate that the app makes a sound every time s...          1\n",
      "4      useless at bse star mf meetvoice too mych slow...          0\n",
      "...                                                  ...        ...\n",
      "40513  is good to show my everyday living example as ...          2\n",
      "40514                                very good this apps          1\n",
      "40515  the app was very good until recently im not ab...          1\n",
      "40516  i cant see any background effects there is no ...          1\n",
      "40517  unable to login from browser the whole day tod...          0\n",
      "\n",
      "[40518 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "# define a regular expression function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # return preprocessed text\n",
    "    return text\n",
    "\n",
    "\n",
    "# apply the preprocessing function to the text column of the dataframe\n",
    "df['review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# display the preprocessed text\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_JHVudc6_3c"
   },
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                       aditya ingole deaf\n",
      "1        i love the app there is no issue but if u coul...\n",
      "2        so hard to use the web app failed and the mobi...\n",
      "3        i hate that the app makes a sound every time s...\n",
      "4        useless at bse star mf meetvoice too mych slow...\n",
      "                               ...                        \n",
      "40513    is good to show my everyday living example as ...\n",
      "40514                                  very good this apps\n",
      "40515    the app was very good until recently im not ab...\n",
      "40516    i cant see any background effects there is no ...\n",
      "40517    unable to login from browser the whole day tod...\n",
      "Name: review, Length: 40518, dtype: object\n",
      "0        2\n",
      "1        1\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "40513    2\n",
      "40514    1\n",
      "40515    1\n",
      "40516    1\n",
      "40517    0\n",
      "Name: sentiment, Length: 40518, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split the DataFrame into features and labels\n",
    "X = df['review']  \n",
    "y = df['sentiment']               # select only the target column as the label\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jcuWjtES7CgQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 32414\n",
      "Test set size: 8104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print the size of the training and test sets\n",
    "print(f'Training set size: {len(X_train)}')\n",
    "print(f'Test set size: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKlXhfOI7dyJ"
   },
   "source": [
    "### apply vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "mO4Hv_7j7hgZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (40518, 20399)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# fit the vectorizer to the text data\n",
    "vectorizer.fit(df['review'])\n",
    "\n",
    "# transform the text data into a matrix of features\n",
    "X = vectorizer.transform(df['review'])\n",
    "\n",
    "# print the shape of the feature matrix\n",
    "print(f'Feature matrix shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfx24fAz7iGK"
   },
   "source": [
    "### create pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "NivIYjzX7o2F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6578232971372162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fawzia\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create a pipeline with CountVectorizer and LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# fit the pipeline to the data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the pipeline on the test data\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(f'Accuracy: {score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvfWkUXV7v1B"
   },
   "source": [
    "### print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "F1t8R7rE7yRZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      2676\n",
      "           1       0.54      0.45      0.49      2324\n",
      "           2       0.69      0.79      0.74      3104\n",
      "\n",
      "    accuracy                           0.66      8104\n",
      "   macro avg       0.64      0.64      0.64      8104\n",
      "weighted avg       0.65      0.66      0.65      8104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predict labels for the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
